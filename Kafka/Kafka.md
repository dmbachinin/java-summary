# Kafka

```plantext
    Apache Kafka — это распределённая система обработки событий и потоковой передачи данных в реальном времени. Она используется для построения масштабируемых систем обмена сообщениями, которые могут обрабатывать большие объёмы данных с низкой задержкой.
```

- [Kafka](#kafka)
  - [Применение Kafka](#применение-kafka)
    - [1. Обработка потоков данных (Stream Processing)](#1-обработка-потоков-данных-stream-processing)
    - [2. Интеграция между системами (Event-Driven Architecture)](#2-интеграция-между-системами-event-driven-architecture)
    - [3. Логирование и аудит](#3-логирование-и-аудит)
    - [4. Событийное хранилище (Event Store)](#4-событийное-хранилище-event-store)
    - [5. Масштабируемая очередь сообщений](#5-масштабируемая-очередь-сообщений)
    - [6. Объединение данных (Data Integration)](#6-объединение-данных-data-integration)
    - [7. Работа с большими данными (Big Data)](#7-работа-с-большими-данными-big-data)
    - [Почему Kafka — это не просто очередь сообщений?](#почему-kafka--это-не-просто-очередь-сообщений)
    - [Когда Kafka не подходит?](#когда-kafka-не-подходит)
  - [Основные понятия и особенности Kafka](#основные-понятия-и-особенности-kafka)
  - [Для чего нужны топики и партиции?](#для-чего-нужны-топики-и-партиции)
  - [Как работает Kafka?](#как-работает-kafka)

## Применение Kafka

Kafka подходит для масштабируемой и асинхронной обработки данных в реальном времени, интеграции систем и построения событийных архитектур. Если вам нужна платформа для потоковой обработки данных, объединения микросервисов или работы с большими объёмами событий, Kafka — это правильный выбор. Однако для синхронных запросов и ответов лучше использовать другие инструменты. Вот основные случаи, когда Kafka становится незаменимым инструментом:

---

### 1. Обработка потоков данных (Stream Processing)

Kafka идеально подходит для работы с потоковыми данными в реальном времени. Это может быть полезно для:

- **Мониторинга событий**: Логи, метрики серверов, события приложений.
- **Анализа данных в реальном времени**: Например, подсчёт количества пользователей на веб-сайте или обработка данных с устройств IoT.
- **Потоковой аналитики**: Например, определение трендов или отклонений в данных на лету.

С помощью **Kafka Streams API** или **ksqlDB**, Kafka позволяет выполнять такие операции, как:

- Фильтрация данных.
- Агрегация (например, подсчёт или суммирование).
- Объединение потоков данных из разных топиков.

---

### 2. Интеграция между системами (Event-Driven Architecture)

Kafka отлично подходит для передачи событий между сервисами в архитектуре, основанной на событиях. В таких системах:

- Один сервис (Producer) публикует событие в топик Kafka.
- Другие сервисы (Consumers) обрабатывают это событие асинхронно.

Примеры:

- Когда пользователь завершает заказ в интернет-магазине, Kafka может отправить события в топики:
  - для обновления склада,
  - для расчёта аналитики,
  - для уведомления клиента.

Это обеспечивает слабую связанность между сервисами: каждый сервис знает только о данных из Kafka, а не о других сервисах.

---

### 3. Логирование и аудит

Kafka используется для централизованного сбора и хранения логов из распределённых систем. Например:

- Приложения отправляют логи в Kafka.
- Kafka передаёт эти логи в системы обработки (например, Elasticsearch или Splunk) для последующего анализа.

Это обеспечивает высокую производительность и надёжность для логирования в реальном времени.

---

### 4. Событийное хранилище (Event Store)

Kafka может работать как долгосрочное хранилище событий. Это используется для:

- **Сохранения истории изменений данных**: Например, каждое изменение в профиле пользователя записывается как событие.
- **Реализации паттерна "CQRS"**: Разделение системы на две части: командную (Command) и запросную (Query).

---

### 5. Масштабируемая очередь сообщений

Хотя Kafka не является классической очередью сообщений, она подходит для задач, где:

- Важна высокая производительность и низкая задержка.
- Данные должны быть обработаны параллельно.
- Нужно поддерживать порядок обработки сообщений в пределах партиции.

Пример: обработка задач в распределённой системе, таких как загрузка изображений или рендеринг видео.

---

### 6. Объединение данных (Data Integration)

Kafka часто используется как "шина данных" для интеграции между различными системами. Например:

- Извлечение данных из базы данных (CDC — Change Data Capture).
- Объединение данных из нескольких источников (например, из MySQL, PostgreSQL, MongoDB).
- Отправка данных в аналитические системы (например, Apache Hadoop, Apache Spark).

С помощью Kafka Connect можно подключать различные источники и приёмники данных без написания большого количества кода.

---

### 7. Работа с большими данными (Big Data)

Kafka используется как "посредник" для передачи огромных объёмов данных в экосистему Big Data:

- Данные отправляются из приложений или сенсоров в Kafka.
- Оттуда они поступают в Spark, Flink или Hadoop для обработки.

---

### Почему Kafka — это не просто очередь сообщений?

Kafka может быть использована как очередь сообщений, но она значительно мощнее классических систем, таких как RabbitMQ или ActiveMQ. Вот её отличительные особенности:

1. **Масштабируемость**:
   - Топики с партициями позволяют распределять нагрузку на несколько брокеров и потребителей.

2. **Хранение данных**:
   - Kafka сохраняет сообщения на диске, что позволяет повторно считывать их в любое время.
   - Это выгодно для аналитики и повторной обработки данных.

3. **Высокая пропускная способность**:
   - Kafka оптимизирована для передачи больших объёмов данных с низкой задержкой.

4. **Отказоустойчивость**:
   - Репликация партиций обеспечивает сохранность данных даже при сбое одного из брокеров.

5. **Асинхронная архитектура**:
   - Kafka идеально подходит для случаев, когда не требуется мгновенный ответ от другого сервиса.

---

### Когда Kafka не подходит?

1. **Синхронное взаимодействие**:
   - Если один сервис должен получить ответ от другого сразу, лучше использовать REST, gRPC или другие протоколы RPC.

2. **Малые объёмы данных**:
   - Kafka оптимизирована для работы с большими объёмами данных. Для небольших задач она может быть избыточной.

3. **Сложная маршрутизация сообщений**:
   - Kafka не предоставляет "умной" маршрутизации сообщений, как RabbitMQ.

---

## Основные понятия и особенности Kafka

1. **События и сообщения**:
   - Kafka работает с концепцией событий или сообщений. Событие — это запись, содержащая ключ, значение, временную метку и метаданные.
   - Пример события: запись о покупке, лог-сообщение или данные от сенсора IoT.

2. **Производители (Producers)**:
   - Производители отправляют данные в Kafka.
   - Они выбирают, в какой топик (topic) записать сообщение, и могут указывать ключ для маршрутизации данных в определённые партиции.

3. **Потребители (Consumers)**:
   - Потребители считывают данные из Kafka.
   - Они могут быть объединены в группы потребителей, где каждая группа отвечает за обработку определённого набора сообщений.

4. **Брокеры (Brokers)**:
   - Kafka-кластер состоит из одного или нескольких брокеров (серверов).
   - Каждый брокер отвечает за хранение части данных и обеспечивает их доступность.

5. **Топики (Topics)**:
   - Топик — это логический канал, через который передаются сообщения.
   - Данные в топике упорядочены и хранятся в неизменяемом виде.
   - Производители отправляют данные в топики, а потребители читают из них.

6. **Партиции (Partitions)**:
   - Топики делятся на партиции. Каждая партиция представляет собой логически независимую часть топика.
   - Партиции позволяют масштабировать Kafka, обеспечивая параллельную обработку сообщений.
   - Сообщения в партиции упорядочены по времени добавления, и каждый имеет уникальный смещение (offset).

## Для чего нужны топики и партиции?

1. **Топики**:
   - Обеспечивают логическую сегментацию данных.
   - Например, можно создать разные топики для логов приложения, аналитики пользователей и событий IoT.

2. **Партиции**:
   - Увеличивают производительность и масштабируемость Kafka.
   - Данные могут быть распределены между несколькими серверами, чтобы избежать узких мест.
   - Партиции упрощают параллельную обработку, так как потребители могут обрабатывать данные из разных партиций одновременно.

## Как работает Kafka?

1. **Запись данных**:
   - Производители отправляют сообщения в определённый топик.
   - Kafka записывает данные на диск для обеспечения надёжности.

2. **Чтение данных**:
   - Потребители считывают данные из топика.
   - Потребитель может сохранять текущий offset, чтобы знать, с какого места продолжить обработку.

3. **Механизм хранения**:
   - Данные хранятся на диске в течение определённого времени (по умолчанию 7 дней) или до достижения заданного объёма.

4. **Репликация**:
   - Каждая партиция имеет несколько реплик для обеспечения отказоустойчивости.
   - Если один брокер выходит из строя, данные остаются доступными на других брокерах.
